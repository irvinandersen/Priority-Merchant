{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc1ef156-8d06-4cee-9118-78654b405655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "import urllib.request\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import ast\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "import math\n",
    "import re\n",
    "\n",
    "import dataframe_image as dfi\n",
    "import seaborn as sns\n",
    "import dateutil.relativedelta\n",
    "from io import BytesIO\n",
    "import win32clipboard\n",
    "from PIL import Image\n",
    "import sys\n",
    "import cv2\n",
    "import schedule\n",
    "import locale\n",
    "import zipfile\n",
    "import chromedriver_autoinstaller\n",
    "import io\n",
    "from io import StringIO\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9d7016-b86d-4169-89ea-afad08a9f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50e3239c-e143-47fc-ac53-bf731d5b7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    for i in range(0,30):\n",
    "        while True:\n",
    "            try:\n",
    "                sa = gspread.service_account(filename='irvin-kupu-347a55c7b154.json')\n",
    "                \n",
    "                post_sh = sa.open(\"BANK DATA\")\n",
    "\n",
    "                troops_wks = post_sh.worksheet(\"Ground Troops Data\")\n",
    "\n",
    "                troops_list = troops_wks.get_all_values()\n",
    "\n",
    "                all_troops_df = pd.DataFrame(troops_list[1:], columns=troops_list[0])\n",
    "                \n",
    "                troops_status = all_troops_df[['Agent Code ','Status']]\n",
    "\n",
    "                s = requests.Session()\n",
    "\n",
    "                s.headers.update({'authorization': 'Basic YXBpLWdhdGV3YXk6dGVzdA=='})\n",
    "\n",
    "                payload_login_man = {\"username\":\"irvin\", \"password\":\"@Indonesia2\", \"grant_type\":\"password\", \"scope\":\"read\"}\n",
    "\n",
    "                res_login_man = s.post('https://api.kupu.id/sso/oauth/token',  payload_login_man )\n",
    "\n",
    "                print('Login Sucess')\n",
    "\n",
    "                s.headers.update({'authorization': 'Bearer '+  json.loads(res_login_man.content)['access_token']})\n",
    "                s.headers.update({'authorize-tag': 'bigdata'})\n",
    "                s.headers.update({'token': json.loads(res_login_man.content)['access_token']})\n",
    "\n",
    "                params_idsp = {\"pageSize\": 40 , \"pageNum\":1}\n",
    "\n",
    "                res_idsp = s.get('https://bi.kupu.id/prod-api/bi/data/2/getPublicExportListToOv',  params = params_idsp )\n",
    "\n",
    "                for i in range(len(json.loads(res_idsp.content)['rows'])):\n",
    "                    temp = json.loads(res_idsp.content)['rows'][i]['downLoadPath']\n",
    "                    if 'job' in temp.lower() and 'provider' in temp.lower() and 'V' in temp:\n",
    "                        provider_link = temp\n",
    "\n",
    "                print('Downloading Job Provider Data')\n",
    "\n",
    "                res_provider = s.get(provider_link)\n",
    "\n",
    "                job_provider_df = pd.read_excel(res_provider.content, index_col= 'no')\n",
    "                \n",
    "                job_provider_df_drop = job_provider_df[['full_name', 'job_provider_id', 'business_id', 'device_id']]\n",
    "\n",
    "                for i in range(len(json.loads(res_idsp.content)['rows'])):\n",
    "                    temp = json.loads(res_idsp.content)['rows'][i]['downLoadPath']\n",
    "                    if 'job' in temp.lower() and 'detail' in temp.lower() and 'info' in temp.lower():\n",
    "                        link = temp     \n",
    "\n",
    "                print('Downloading Job Detail Data')\n",
    "\n",
    "                res_login_man = s.get(link)\n",
    "\n",
    "                job_detail_df = pd.read_excel(res_login_man.content)\n",
    "                \n",
    "                job_detail_this_month = job_detail_df\n",
    "                \n",
    "                job_provider_col = job_provider_df[['join_date', 'business_id', 'business_name',  'full_name', 'industry', 'inviter_full_name', 'invitation_code', 'number_of_staff', 'job_provider_id']]\n",
    "\n",
    "                job_detail_col = job_detail_df[['user_id','business_name', 'city', 'applied', 'offered', 'accepted', 'rejected', 'declined', 'job_vacancy','time_of_post', 'time_of_accepted', 'status']]\n",
    "                \n",
    "                job_detail_numbers = job_detail_col.groupby('user_id').sum()\n",
    "                \n",
    "                job_detail_numbers_index = job_detail_numbers.reset_index(drop= False)\n",
    "                \n",
    "                job_detail_col['Time of accepted List'] = job_detail_col['time_of_accepted'].str.split(',')\n",
    "\n",
    "                divided_accepted_time = job_detail_col.explode('Time of accepted List')\n",
    "\n",
    "                divided_accepted_time = divided_accepted_time.dropna(subset=['Time of accepted List'])\n",
    "\n",
    "                divided_accepted_time['time_of_post'] = pd.to_datetime(divided_accepted_time['time_of_post'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                divided_accepted_time['Time of accepted List'] = pd.to_datetime(divided_accepted_time['Time of accepted List'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                job_prov_id_list = divided_accepted_time['user_id'].unique()\n",
    "\n",
    "                job_detail_numbers_index['Average Accepted Time'] = '-'\n",
    "\n",
    "                job_detail_numbers_index['Convertion Rate'] = ''\n",
    "\n",
    "                job_detail_numbers_index['Status'] = 'Close'\n",
    "                \n",
    "                job_detail_numbers_index['Num of Job Post'] = 0\n",
    "                \n",
    "                job_detail_status = job_detail_col[['user_id', 'status']].drop_duplicates()\n",
    "                \n",
    "                job_prov_id_list_two = job_detail_this_month['user_id'].unique()\n",
    "\n",
    "                for ids in job_prov_id_list_two:\n",
    "                    job_prov_group_two = job_detail_this_month.groupby('user_id')\n",
    "                    each_job_prov_df_two = job_prov_group_two.get_group(ids)\n",
    "                    num_of_post = len(each_job_prov_df_two)\n",
    "                    \n",
    "                    job_detail_numbers_index['Num of Job Post'] = np.where((job_detail_numbers_index['user_id'] == ids) , num_of_post , job_detail_numbers_index['Num of Job Post'])\n",
    "\n",
    "                for job_prov_id in job_prov_id_list:\n",
    "                    job_prov_group = divided_accepted_time.groupby('user_id')\n",
    "                    each_job_prov_df = job_prov_group.get_group(job_prov_id)\n",
    "                    \n",
    "                    total_time = 0 \n",
    "\n",
    "                    for index, row in each_job_prov_df[['time_of_post', 'Time of accepted List']].iterrows():\n",
    "                        date_range = (row['Time of accepted List'] - row['time_of_post']).total_seconds()\n",
    "                        total_time += date_range\n",
    "                        average_time = total_time / len(each_job_prov_df)\n",
    "\n",
    "                    average_day = str(\"{:.1f}\".format(average_time/60/60/24)) \n",
    "\n",
    "                    job_detail_numbers_index['Average Accepted Time'] = np.where((job_detail_numbers_index['user_id'] == job_prov_id) , average_day + ' Days' , job_detail_numbers_index['Average Accepted Time'])\n",
    "                    \n",
    "                    job_prov_status = job_detail_status.groupby('user_id')\n",
    "                    each_job_prov_status_df = job_prov_status.get_group(job_prov_id)\n",
    "\n",
    "                    if len(each_job_prov_status_df) > 1:\n",
    "                        job_detail_numbers_index['Status'] = np.where((job_detail_numbers_index['user_id'] == job_prov_id) , 'Open' , job_detail_numbers_index['Status'])\n",
    "\n",
    "                job_detail_numbers_index['Convertion Rate'] = job_detail_numbers_index['accepted'] / job_detail_numbers_index['job_vacancy'] * 100\n",
    "\n",
    "                job_detail_numbers_index['Convertion Rate'] = job_detail_numbers_index['Convertion Rate'].fillna(0)\n",
    "\n",
    "                job_detail_numbers_index['Convertion Rate'] = job_detail_numbers_index['Convertion Rate'].round(2)\n",
    "\n",
    "                job_detail_numbers_index['Convertion Rate'] = job_detail_numbers_index['Convertion Rate'].astype(str) + '%' \n",
    "                \n",
    "                job_detail_city = job_detail_col[['user_id', 'city']]\n",
    "                \n",
    "                job_detail_city_no_dup = job_detail_city.drop_duplicates(subset=['user_id'])\n",
    "                \n",
    "                job_detail_all = job_detail_numbers_index.merge(job_detail_city_no_dup , how ='left', on = 'user_id', suffixes=(False, False))\n",
    "                \n",
    "                job_provider_and_post = job_provider_col.merge(job_detail_all , how ='left', left_on = 'job_provider_id', right_on = 'user_id', suffixes=(False, False))\n",
    "                \n",
    "                job_provider_and_post['Average Accepted Time'].fillna('-')\n",
    "                \n",
    "                job_provider_and_post_status = job_provider_and_post.merge(troops_status , how ='left', left_on = 'invitation_code', right_on = 'Agent Code ')\n",
    "                \n",
    "                job_provider_and_post_status['applied'] = job_provider_and_post_status['applied'].fillna(0)\n",
    "                \n",
    "                job_provider_and_post_status['offered'] = job_provider_and_post_status['offered'].fillna(0)\n",
    "                \n",
    "                job_provider_and_post_status['accepted'] = job_provider_and_post_status['accepted'].fillna(0)\n",
    "                \n",
    "                job_provider_and_post_status['applied'] = job_provider_and_post_status['applied'].fillna(0)\n",
    "                \n",
    "                job_provider_and_post_status['rejected'] = job_provider_and_post_status['rejected'].fillna(0)\n",
    "                \n",
    "                job_provider_and_post_status['declined'] = job_provider_and_post_status['declined'].fillna(0)\n",
    "                \n",
    "                job_provider_and_post_status['job_vacancy'] = job_provider_and_post_status['job_vacancy'].fillna(0)\n",
    "                \n",
    "                job_provider_and_post_status['Num of Job Post'] = job_provider_and_post_status['Num of Job Post'].fillna(0)\n",
    "                \n",
    "                job_provider_and_post_status['applied'] = job_provider_and_post_status['applied'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['offered'] = job_provider_and_post_status['offered'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['accepted'] = job_provider_and_post_status['accepted'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['applied'] = job_provider_and_post_status['applied'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['rejected'] = job_provider_and_post_status['rejected'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['declined'] = job_provider_and_post_status['declined'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['job_vacancy'] = job_provider_and_post_status['job_vacancy'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['Num of Job Post'] = job_provider_and_post_status['Num of Job Post'].astype(int)\n",
    "\n",
    "                \n",
    "                job_provider_and_post_status = job_provider_and_post_status[['join_date','business_id','business_name', 'job_provider_id', 'full_name','industry','city', 'Status_x','inviter_full_name','invitation_code', 'Status_y','number_of_staff',\n",
    "\n",
    "                                                                             'applied', 'offered', 'accepted', 'rejected', 'declined', 'Num of Job Post', 'job_vacancy', 'Average Accepted Time',\n",
    "                                                                            'Convertion Rate']]\n",
    "                \n",
    "                job_provider_and_post_status.columns = ['join_date','business_id','business_name', 'job_provider_id',\n",
    "                                                                             'full_name','industry','city', 'merchant_status','inviter_full_name','invitation_code', 'agent_status','number_of_staff',\n",
    "                                                                            'applied', 'offered', 'accepted', 'rejected', 'declined','Num of Job Post', 'job_vacancy', 'Average Accepted Time',\n",
    "                                                                            'Convertion Rate']\n",
    "                                \n",
    "                job_detail_drop = job_detail_this_month.drop(columns=['user_job_id', 'payment',  'job_vacancy', 'job_description', 'job_type'])\n",
    "                \n",
    "                job_detail_accepted = job_detail_drop[job_detail_drop['accepted'] > 0]\n",
    "                \n",
    "                job_provider_df_drop.columns = ['full_name', 'job_provider_id', 'business_id', 'jp_device_id']\n",
    "                \n",
    "                job_detail_and_provider = job_detail_accepted.merge(job_provider_df_drop, left_on='user_id', right_on='job_provider_id')\n",
    "                \n",
    "                business_id_list = job_detail_and_provider['business_id'].drop_duplicates().reset_index(drop = True)\n",
    "                \n",
    "                ended_lists = []\n",
    "                \n",
    "                print('Download Data from MAN KUPU 1')\n",
    "\n",
    "                for business_id in business_id_list:\n",
    "                    params_offered = {\"pageSize\": 500 , \"companyId\":business_id, \"businessId\":business_id, \"status\":7}\n",
    "\n",
    "                    res_offered = s.get('https://man.kupu.id/prod-api/position/offer/selectAllOfferByCompany',  params = params_offered )\n",
    "\n",
    "                    isi = json.loads(res_offered.content)\n",
    "\n",
    "                    if len(isi['body']['records']) == 0:\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        for number in range(len(isi['body']['records'])):\n",
    "                            temp_list = [isi['body']['records'][number]['company']['id'] , isi['body']['records'][number]['job']['id'], isi['body']['records'][number]['company']['createUserId'], isi['body']['records'][number]['employee']['userId']]\n",
    "                            ended_lists.append(temp_list)\n",
    "                            \n",
    "                ended_df = pd.DataFrame(ended_lists, columns=['Business ID', 'Job ID', 'Provider ID', 'Seeker ID'])\n",
    "                \n",
    "                accepted_lists = []\n",
    "                \n",
    "                print('Download Data from MAN KUPU 2')\n",
    "\n",
    "                for business_id in business_id_list:\n",
    "                    params_offered = {\"pageSize\": 500 , \"companyId\":business_id, \"businessId\":business_id, \"status\":1}\n",
    "\n",
    "                    res_offered = s.get('https://man.kupu.id/prod-api/position/offer/selectAllOfferByCompany',  params = params_offered )\n",
    "\n",
    "                    isi = json.loads(res_offered.content)\n",
    "\n",
    "                    if len(isi['body']['records']) == 0:\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        for number in range(len(isi['body']['records'])):\n",
    "                            temp_list = [isi['body']['records'][number]['company']['id'] , isi['body']['records'][number]['job']['id'], isi['body']['records'][number]['company']['createUserId'], isi['body']['records'][number]['employee']['userId']]\n",
    "                            accepted_lists.append(temp_list)\n",
    "                            \n",
    "                accepted_df = pd.DataFrame(accepted_lists, columns=['Business ID', 'Job ID', 'Provider ID', 'Seeker ID'])\n",
    "                \n",
    "                all_accepted_df = ended_df.append(accepted_df, ignore_index=True)\n",
    "                \n",
    "                all_accepted_df_seeker_only = all_accepted_df[['Job ID', 'Seeker ID']]\n",
    "                \n",
    "                job_detail_and_provider['job_id'] = job_detail_and_provider['job_id'].astype(str)\n",
    "                \n",
    "                job_detail_and_provider_seeker_id = job_detail_and_provider.merge(all_accepted_df_seeker_only, left_on = 'job_id', right_on = 'Job ID')\n",
    "                \n",
    "                print('Downloading Job Seekers Data')\n",
    "                \n",
    "                for i in range(len(json.loads(res_idsp.content)['rows'])):\n",
    "                    temp = json.loads(res_idsp.content)['rows'][i]['csvFilePath']\n",
    "                    if 'job' in temp.lower() and 'seeker' in temp.lower() and 'V' in temp and 'zip' in temp.lower():\n",
    "                        seeker_link = temp\n",
    "                \n",
    "                res_login_man = s.get(seeker_link)\n",
    "\n",
    "                man_byte = io.BytesIO(res_login_man.content)\n",
    "\n",
    "                zf = zipfile.ZipFile(man_byte, \"r\")\n",
    "\n",
    "                zip_file = zf.read(zf.namelist()[0])\n",
    "\n",
    "                zip_string =str(zip_file,'utf-8')\n",
    "\n",
    "                job_report = StringIO(zip_string) \n",
    "\n",
    "                job_seeker_df = pd.read_csv(job_report, index_col= 'no')\n",
    "                \n",
    "                job_seeker_df_name  = job_seeker_df[['user_id', 'full_name','device_id', 'mobile_number']]\n",
    "                \n",
    "                job_seeker_df_name.columns = ['user_id', 'full_name','js_device_id', 'mobile_number']\n",
    "                \n",
    "                job_seeker_df_name['user_id'] = job_seeker_df_name['user_id'].astype(str)\n",
    "                \n",
    "                job_detail_and_provider_seeker = job_detail_and_provider_seeker_id.merge(job_seeker_df_name, left_on='Seeker ID', right_on='user_id')\n",
    "                \n",
    "                job_detail_and_provider_seeker_final = job_detail_and_provider_seeker[['business_id','business_name', 'job_id' , 'job_position', 'job_title', \n",
    "                                                                       'salary', 'city', 'applied' ,'offered','accepted','rejected',\n",
    "                                                                       'declined', 'time_of_post', 'time_of_accepted','job_provider_id', 'full_name_x',  \n",
    "                                                                       'jp_device_id', 'Seeker ID', 'full_name_y' , 'js_device_id', 'mobile_number']]\n",
    "                \n",
    "                job_detail_and_provider_seeker_final.columns = ['Business ID','Business Name', 'Job Post ID' , 'Job Position', 'Job Title', \n",
    "                                                                       'Salary', 'City', 'Applied' ,'Offered', 'Accepted', 'Rejected',\n",
    "                                                                       'Declined', 'Time of post', 'Time of accepted','Provider ID', 'Provider Name', 'Provider Device ID', 'Seeker ID', 'Seeker Name', 'Seeker Device ID', 'mobile_number']\n",
    "                                \n",
    "                business_group = job_detail_and_provider_seeker_final.groupby('Business ID')\n",
    "\n",
    "                business_id_list = job_detail_and_provider_seeker_final['Business ID'].unique()\n",
    "                \n",
    "                job_detail_and_provider_seeker_final['Multiple Device JS'] = False\n",
    "                job_detail_and_provider_seeker_final['Multiple Device JS (Count)'] = 0\n",
    "\n",
    "                job_detail_and_provider_seeker_final['JP Same Device as JS'] = False\n",
    "                job_detail_and_provider_seeker_final['JP Same Device as JS (Count)'] = 0\n",
    "\n",
    "                for ids in business_id_list:\n",
    "                    each_business_df = business_group.get_group(ids)\n",
    "                    job_post_id_list = each_business_df['Job Post ID'].unique()\n",
    "\n",
    "                    for job_post_id in job_post_id_list:\n",
    "                        business_job_post_group = each_business_df.groupby('Job Post ID')\n",
    "                        each_job_post_df = business_job_post_group.get_group(job_post_id)\n",
    "\n",
    "                        each_job_post_no_dup = each_job_post_df.drop_duplicates(subset=['Seeker ID'])\n",
    "                        divided_js_device_id = each_job_post_no_dup['Seeker Device ID'].str.split('，')\n",
    "                        all_divided_js_device_id = divided_js_device_id.explode('Seeker Device ID').dropna().unique()\n",
    "\n",
    "                        all_js_device_id = each_job_post_no_dup['Seeker Device ID']\n",
    "\n",
    "                        for js_device_id in all_divided_js_device_id:      \n",
    "\n",
    "                            js_occur = all_js_device_id.str.contains(js_device_id, na=False).sum()\n",
    "\n",
    "                            if js_occur > 1:\n",
    "\n",
    "                                job_detail_and_provider_seeker_final['Multiple Device JS'] = np.where((job_detail_and_provider_seeker_final['Seeker Device ID'].str.contains(js_device_id, na=False)) \n",
    "                                                                                                      & (job_detail_and_provider_seeker_final['Job Post ID'] == job_post_id) \n",
    "                                                                                                      , True \n",
    "                                                                                                      , job_detail_and_provider_seeker_final['Multiple Device JS'])\n",
    "\n",
    "                                job_detail_and_provider_seeker_final['Multiple Device JS (Count)'] = np.where((job_detail_and_provider_seeker_final['Seeker Device ID'].str.contains(js_device_id, na=False)) \n",
    "                                                                                                              & (job_detail_and_provider_seeker_final['Job Post ID'] == job_post_id) \n",
    "                                                                                                              , job_detail_and_provider_seeker_final['Multiple Device JS (Count)'] + js_occur \n",
    "                                                                                                              , job_detail_and_provider_seeker_final['Multiple Device JS (Count)'])\n",
    "\n",
    "                        each_job_post_no_dup['Provider Device ID List'] = each_job_post_no_dup['Provider Device ID'].str.split(',')\n",
    "\n",
    "                        each_job_post_jp_exploded = each_job_post_no_dup.explode('Provider Device ID List')\n",
    "\n",
    "                        each_job_post_jp_exploded['Seeker Device ID List'] = each_job_post_jp_exploded['Seeker Device ID'].str.split('，')\n",
    "\n",
    "                        each_job_post_jp_js_exploded = each_job_post_jp_exploded.explode('Seeker Device ID List') \n",
    "\n",
    "                        duplicate_count = 0\n",
    "\n",
    "                        for row, data in each_job_post_jp_js_exploded.iterrows():\n",
    "\n",
    "                            if data['Provider Device ID List'] == data['Seeker Device ID List']:\n",
    "\n",
    "                                job_detail_and_provider_seeker_final['JP Same Device as JS'] = np.where((job_detail_and_provider_seeker_final['Seeker Device ID'].str.contains(data['Provider Device ID List'], na=False)) & \n",
    "                                                                                                        (job_detail_and_provider_seeker_final['Provider Device ID'].str.contains(data['Provider Device ID List'], na=False)) \n",
    "                                                                                                      , True \n",
    "                                                                                                      , job_detail_and_provider_seeker_final['JP Same Device as JS'])\n",
    "\n",
    "                                duplicate_count += 1\n",
    "\n",
    "                        job_detail_and_provider_seeker_final['JP Same Device as JS (Count)'] = np.where((job_detail_and_provider_seeker_final['JP Same Device as JS'] == True) &\n",
    "                                                                                                        (job_detail_and_provider_seeker_final['Job Post ID'] == job_post_id) \n",
    "                                                                                                      , duplicate_count\n",
    "                                                                                                      , job_detail_and_provider_seeker_final['JP Same Device as JS (Count)'])\n",
    "                        \n",
    "                        job_detail_and_provider_seeker_final['Not Eligible']  = np.where((job_detail_and_provider_seeker_final['Multiple Device JS'] == True )  | (job_detail_and_provider_seeker_final['JP Same Device as JS'] == True )  , True , False )\n",
    "                        \n",
    "                \n",
    "                all_fraud_sum = job_detail_and_provider_seeker_final.groupby('Provider ID').sum().reset_index(drop=False)\n",
    "                \n",
    "                all_fraud_sum['Multiple Device JS'] = all_fraud_sum['Multiple Device JS'].astype(bool)\n",
    "                \n",
    "                all_fraud_sum['JP Same Device as JS'] = all_fraud_sum['JP Same Device as JS'].astype(bool)\n",
    "                \n",
    "                all_fraud_sum['Not Eligible'] = all_fraud_sum['Not Eligible'].astype(bool)\n",
    "                \n",
    "                all_fraud_sum_clean = all_fraud_sum[['Provider ID','Multiple Device JS','Multiple Device JS (Count)','JP Same Device as JS','JP Same Device as JS (Count)','Not Eligible']]\n",
    "                                                \n",
    "                job_provider_and_post_status = job_provider_and_post_status.merge(all_fraud_sum_clean, how='left' ,left_on='job_provider_id', right_on='Provider ID', suffixes=(False, False))\n",
    "                \n",
    "                job_provider_and_post_status = job_provider_and_post_status.drop(columns=['Provider ID'])\n",
    "                                \n",
    "                job_provider_and_post_status = job_provider_and_post_status.fillna('').astype(str)\n",
    "                                                                                              \n",
    "                job_provider_and_post_status['applied'] = job_provider_and_post_status['applied'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['offered'] = job_provider_and_post_status['offered'].astype(int)\n",
    "                                                                                              \n",
    "                job_provider_and_post_status['accepted'] = job_provider_and_post_status['accepted'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['rejected'] = job_provider_and_post_status['rejected'].astype(int)\n",
    "                                                                                              \n",
    "                job_provider_and_post_status['declined'] = job_provider_and_post_status['declined'].astype(int)\n",
    "                                                                                              \n",
    "                job_provider_and_post_status['job_vacancy'] = job_provider_and_post_status['job_vacancy'].astype(int)\n",
    "                \n",
    "                job_provider_and_post_status['Num of Job Post'] = job_provider_and_post_status['Num of Job Post'].astype(int)\n",
    "                \n",
    "                sa = gspread.service_account(filename='irvin-kupu-347a55c7b154.json')\n",
    "                \n",
    "                post_sh = sa.open(\"BANK DATA\")\n",
    "                \n",
    "                post_wks = post_sh.worksheet(\"Priority Merchant\")\n",
    "                \n",
    "                post_wks.clear()\n",
    "                \n",
    "                post_wks.update([job_provider_and_post_status.columns.values.tolist()] + job_provider_and_post_status.values.tolist())\n",
    "                \n",
    "                break\n",
    "                \n",
    "            except:\n",
    "                print('Email Send Error, retrying in 30s')\n",
    "                time.sleep(30)\n",
    "                \n",
    "                continue\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56cfde20-b32c-4780-9a75-e83a44ca30d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Sucess\n",
      "Downloading Job Provider Data\n",
      "Downloading Job Detail Data\n",
      "Download Data from MAN KUPU 1\n",
      "Download Data from MAN KUPU 2\n",
      "Downloading Job Seekers Data\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cd3b98-4a08-49bc-b8a0-dc3e0d9f4f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Every 1 day at 08:00:00 do run() (last run: [never], next run: 2022-07-26 08:00:00)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule.every().day.at(\"08:00\").do(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff439e-7ca8-45ae-907e-1667387e7c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Sucess\n",
      "Downloading Job Provider Data\n",
      "Downloading Job Detail Data\n",
      "Download Data from MAN KUPU 1\n",
      "Download Data from MAN KUPU 2\n",
      "Downloading Job Seekers Data\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60) # wait one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de288a21-3196-437b-a4f6-a868180b0069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65edd4f-2b4b-4c67-9576-e1162eaca16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
